When we designed and developed ORES, we were targeting a specific problem: expanding the set of values applied to the design of quality control tools to include a recent understanding of the importance of newcomer socialization.  We do not have any direct control of how developers chose to use ORES.  We hypothesize that, by making edit quality predictions available to all developers, we would lower the barrier to experimentation in this space.   After we deployed ORES, we implemented some basic tools to showcase ORES, but we observed a steady adoption of our various prediction models by external developers in current tools and through the development of new tools.\footnote{See complete list: \url{http://enwp.org/:mw:ORES/Applications}}

When we first released ORES, there was a wave of adoption in tools that were already used by Wikipedians.  Machine predictions proved useful as an addition to already-engineered systems used to support content patrolling work.  While this dynamic itself is fascinating, for the purposes of this paper, we focus on the development of new tools that use ORES that may not have been developed at all otherwise.  For example, the Wikimedia Foundation's product department developed a complete redesign on MediaWiki's Special:RecentChanges interface that implements a set of powerful filters and highlighting.  They took the ORES Review Tool to it's logical conclusion with an initiative that they referred to as Edit Review Improvements.\footnote{\url{http://enwp.org/:mw:Edit_Review_Improvements}}  In this interface, ORES scores are prominently featured at the top of the list of available filters, and they have been highlighted as one of the main benefits of the new interface to the editing community.

When we first developed ORES, English Wikipedia was the only wiki that we are aware of that had a fully-automated bot that used machine prediction to automatically revert obvious vandalism \cite{carter2008cluebot}.  After we deployed ORES, several wikis developed such bots of their own using ORES.  For example, PatruBOT in Spanish Wikipedia\footnote{\url{https://es.wikipedia.org/wiki/Usuario:PatruBOT}} and Dexbot in Persian Wikipedia\footnote{\url{https://fa.wikipedia.org/wiki/User:Dexbot}} now automatically revert edits that ORES predicts are damaging with high confidence. 

One of the most noteworthy new applications of ORES is the suite of tools developed by Sage Ross to support the Wiki Education Foundation's\footnote{\url{https://wikiedu.org/}} activities.  Their organization supports classroom activities that involve editing Wikipedia.  They develop tools and dashboards that help students contribute successfully and to help teachers monitor their students' work.  Ross has recently published about how he interprets meaning from ORES' article quality models \cite{ross2016visualizing} (an example of re-appropriation) and he has used the article quality model in their new editor support dashboard\footnote{\url{https://dashboard-testing.wikiedu.org}} in a novel way.  Specifically, Ross's tool\footnote{\url{https://dashboard-testing.wikiedu.org}} uses our feature injection system (see Section~\ref{sec:innovations_in_openness}) to suggest work to new editors.  This system asks ORES to score a student's draft article and then asking ORES to reconsider the predicted quality level of the article with \emph{one more header}, \emph{one more image}, or \emph{one more citation}. In doing so, Ross built an intelligent user interface that can expose the internal structure of a model in order to recommend the most productive development to the article---the change that will most likely bring it to a higher quality level.
