\subsection{ORES system engineering}
\label{sec:ores_system_engineering}
In this section we describe how the system was designed in order to meet the needs of Wikipedian work practices and the tools that support them.

\subsubsection{Scaling \& robustness}


\subsubsection{Empirical access patterns}
\label{sec:appendix.empirical_access_patterns}
\input{figures/ores_activity}

The ORES service has been online since July 2015\cite{halfaker2015artificial}.  Since then, usage has steadily risen as we've developed and deployed new models and additional integrations are made by tool developers and researchers.  Currently, ORES supports 78 different models and 37 different language-specific wikis.

Generally, we see 50 to 125 requests per minute from external tools that are using ORES' predictions (excluding the MediaWiki extension that is more difficult to track).  Sometimes these external requests will burst up to 400-500 requests per second.  Figure~\ref{fig:ores_request_rate} shows the periodic and ``bursty'' nature of scoring requests received by the ORES service.  For example, every day at about 11:40 UTC, the request rate jumps---most likely a batch scoring job such as a bot.

Figure~\ref{fig:ores_precache_rate} shows the rate of precaching requests coming from our own systems.  This graph roughly reflects the rate of edits that are happening to all of the wikis that we support since we'll start a scoring job for nearly every edit as it happens.  Note that the number of precaching requests is about an order of magnitude higher than our known external score request rate.  This is expected, since Wikipedia editors and the tools they use will not request a score for every single revision.  This is a computational price we pay to attain a high cache hit rate and to ensure that our users get the quickest possible response for the scores that they \emph{do} need.

Taken together these strategies allow us to optimize the real-time quality control workflows and batch processing jobs of Wikipedians and their tools.  Without serious effort to make sure that ORES is practically fast and highly available to real-time use cases, ORES would become irrelevant to the target audience and thus irrelevant as a boundary-lowering intervention.  By engineering a system that conforms to the work-process needs of Wikipedians and their tools, we've built a systems intervention that has the potential gain wide adoption in Wikipedia's technical ecology.

\subsection{Explicit pipelines}
\label{sec:appendix.explicit_pipelines}
We have designed the process of training and deploying ORES prediction models to be repeatable and reviewable.  Consider the code shown in figure~\ref{fig:english_damaging_makefile} that represents a common pattern from our model-building Makefiles.

Essentially, this code helps someone determine where the labeled data comes from (manually labeled via the Wiki Labels system).  It makes it clear how features are extracted (using the \texttt{revscoring extract} utility and the \texttt{feature\_lists.enwiki.damaging} feature set).  Finally, this dataset of extracted features is used to cross-validate and train a model predicting the ``damaging'' label and a serialized version of that model is written to a file.  A user could clone this repository, install the set of requirements, and run \texttt{make enwiki\_models} and expect that all of the data-pipeline would be reproduced, and an equivalent model obtained.

By explicitly using public resources and releasing our utilities and Makefile source code under an open license (MIT), we have essentially implemented a turn-key process for replicating our model building and evaluation pipeline.  A developer can review this pipeline for issues knowing that they are not missing a step of the process because all steps are captured in the Makefile.  They can also build on the process (e.g. add new features) incrementally and restart the pipeline.  In our own experience, this explicit pipeline is extremely useful for identifying the origin of our own model building bugs and for making incremental improvements to ORES' models.

At the very base of our Makefile, a user can run \texttt{make models} to rebuild all of the models of a certain type.  We regularly perform this process ourselves to ensure that the Makefile is an accurate representation of the data flow pipeline.  Performing complete rebuild is essential when a breaking change is made to one of our libraries.  The resulting serialized models are saved to the source code repository so that a developer can review the history of any specific model and even experiment with generating scores using old model versions.

\begin{figure}[h]
        \makebox{\hrulefill}{
        \small
        \begin{verbatim}
datasets/enwiki.human_labeled_revisions.20k_2015.json:
    ./utility fetch_labels \
        https://labels.wmflabs.org/campaigns/enwiki/4/ > $@

datasets/enwiki.labeled_revisions.w_cache.20k_2015.json: \
        datasets/enwiki.labeled_revisions.20k_2015.json
    cat $< | \
        revscoring extract \
            editquality.feature_lists.enwiki.damaging \
            --host https://en.wikipedia.org \
            --extractor $(max_extractors) \
            --verbose > $@

models/enwiki.damaging.gradient_boosting.model: \
        datasets/enwiki.labeled_revisions.w_cache.20k_2015.json
    cat $^ | \
    revscoring cv_train \
        revscoring.scoring.models.GradientBoosting \
        editquality.feature_lists.enwiki.damaging \
        damaging \
        --version=$(damaging_major_minor).0 \
        -p 'learning_rate=0.01' \
        -p 'max_depth=7' \
        -p 'max_features="log2"' \
        -p 'n_estimators=700' \
        --label-weight $(damaging_weight) \
        --pop-rate "true=0.034163555464634586" \
        --pop-rate "false=0.9658364445353654" \
        --center --scale > $@
        \end{verbatim}
        \hrule
        \normalsize}
        \caption{Makefile rules for the English damage detection model from \url{https://github.com/wiki-ai/editquality}}
        \label{fig:english_damaging_makefile}
\end{figure}