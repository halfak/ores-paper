Wikipedia---the free encyclopedia that anyone can edit---faces many challenges in maintaining the quality of its articles and sustaining the volunteer community of editors. The people behind the hundreds of different language versions of Wikipedia have long relied on automation, bots, expert systems, recommender systems, human-in-the-loop assisted tools, and machine learning to help moderate and manage content at massive scales. The issues around artificial intelligence in Wikipedia are as complex as those facing other large-scale user-generated content platforms like Facebook, Twitter, or YouTube, as well as traditional corporate and governmental organizations that must make and manage decisions at scale. And like in those organizations, Wikipedia's automated classifiers are raising new and old issues about truth, power, responsibility, openness, and representation.

Yet Wikipedia's approach to AI has long been different than in corporate or governmental contexts typically discussed in emerging fields like Fairness, Accountability, and Transparency in Machine Learning (FATML) or Critical Algorithms Studies (CAS). The volunteer community of editors has strong ideological principles of openness, decentralization, and consensus-based decision-making. The paid staff at the non-profit Wikimedia Foundation---which legally owns and operates the servers---are not tasked with making editorial decisions about content\footnote{Except in rare cases, such as content that violates U.S. law, see \url{http://enwp.org/WP:OFFICE}}. This is instead the responsibility of the volunteer community, where a self-selected set of developers build tools, bots, and advanced technologies in broad consultation with the community. Even though Wikipedia's longstanding socio-technical system of algorithmic governance is far more open, transparent, and accountable than most platforms operating at Wikipedia's scale, ORES\footnote{\url{https://ores.wikimedia.org}}\footnote{\url{http://enwp.org/:mw:ORES}}, the system we present in this paper, pushes even further on the crucial issue of who is able to participate in the development and use of advanced technologies.

ORES represents several innovations in openness in machine learning, particularly in seeing openness as a socio-technical challenge that is as much about scaffolding support as it is about open-sourcing code and data. With ORES, volunteers can curate labeled training data from a variety of sources for a particular purpose, commission the production of a machine classifier based on particular approaches and parameters, and make this classifier available via an API which anyone can query to score any edit to a page---operating in real time on the Wikimedia Foundation's servers. Currently, 78 classifiers have been produced for 37 languages---classifing edits in real-time based on criteria like ``damaging / not damaging,'' ``good faith / bad faith,'' or a language-specific article quality scale. ORES intentionally does not seek to produce a single classifier to enforce a gold standard of quality, nor does it prescribe particular ways in which scores and classifications will be incorporated into fully automated bots and semi-automated editing interfaces. Instead, ORES was built as a kind of cultural probe \cite{hutchinson2003technology} to support an open-ended set of community efforts to re-imagine what machine learning in Wikipedia is and who it is for.

\subsection{Audiences for this work}
Open participation in machine learning is widely relevant to both researchers of user-generated content platforms and those working across open collaboration, social computing, machine learning, and critical algorithms studies.

To the FATML/CAS communities, we introduce an open-by-design algorithmic platform that is widely used to maintain a critical information resource. This socio-technical system implements several of the dominant recommendations for algorithmic system builders around transparency and community consent\cite{crawford2016algorithm,diakopoulos2015algorithmic,gillespie2014relevance,tufekci2015algorithms,sandvig2014auditing}.  Through the deployment of this system and subsequent design iterations, we discuss practical considerations for what openness, accountability, and transparency mean in a large-scale, real-world user-generated content platform.

To algorithmic system-builders, we describe how we have approached key issues in developing a working, scalable, and robust system that matches the decentralized work practices of end-users in Wikipedia.  Some of these approaches apply well-described techniques (e.g. distributed processing and caching,) while others are emergent strategies for giving tool developers and their users flexibility over how to use and understand ORES's algorithmic predictions (e.g. collaborative labeling and model interrogation).

To researchers of social computing systems, we discuss a socio-technical system that supports a novel type of collaborative meta-work. ORES makes it possible for volunteers to commission the production of machine learning classifiers, which others can use to support communities of practice. In this paper, we detail this system's design as it was built to align with the particular ways in which volunteers work in Wikipedia. We also describe how ORES has altered the meta-work of Wikimedia tool developers.

In this paper, we first review related literature around open algorithmic systems, then discuss the socio-technical context of Wikipedia and the design rationale that lead us to building ORES.  Next, we describe how we engineered the ORES system to match Wikipedian work practices -- including innovations we made in algorithmic \emph{openness} and \emph{transparency}. We present a small set of case studies of uses and critiques of ORES' predictions, which demonstrate the effectiveness of the system in broadening conversations about machine learning.  Finally, we conclude with a discussion of the issues raised by this work with our target audiences: FATML/CAS researchers, algorithmic system-builders, and social computing researchers.
